#!/usr/bin/env ruby
# frozen_string_literal: true

require "bundler/setup"
require "json"
require "csv"
require "dotenv"

# Load environment variables
Dotenv.load

# Article Generator MVP
# Generates a complete SEO article with SERP research, outline, and writing
# Uses your voice from Twitter data but maintains proper grammar

class ArticleGenerator
  def initialize(keyword)
    @keyword = keyword
    @voice_profile = load_voice_profile
    @costs = []
  end

  def generate
    puts "üöÄ Generating article for: '#{@keyword}'"
    puts "=" * 80

    # Step 1: Research what's currently ranking
    puts "\nüìä Step 1: Researching top-ranking content..."
    serp_research = research_serp

    # ABORT if search failed
    if serp_research[:data].nil? || serp_research[:data].empty?
      puts "\n‚ùå ABORTED: Google search returned no results"
      exit 1
    end

    log_cost("SERP Research", serp_research[:cost])

    # Step 2: Generate outline
    puts "\nüìù Step 2: Generating outline..."
    outline = generate_outline(serp_research[:data])

    # ABORT if outline generation failed
    if outline[:data].nil? || outline[:data].empty? || outline[:data]['sections'].nil?
      puts "\n‚ùå ABORTED: Outline generation failed"
      show_costs
      exit 1
    end

    log_cost("Outline Generation", outline[:cost])

    # Step 3: Write article
    puts "\n‚úçÔ∏è  Step 3: Writing article..."
    article = write_article(outline[:data])
    log_cost("Article Writing", article[:cost])

    # Step 4: Add tool placeholders
    puts "\nüõ†Ô∏è  Step 4: Adding tool placeholders..."
    article_with_tools = add_tool_placeholders(article[:data], outline[:data])

    # Step 5: Self-improvement passes (3 iterations)
    puts "\nüîç Step 5: Running self-improvement analysis (3 passes)..."
    improved = article_with_tools
    total_improvement_cost = 0

    3.times do |i|
      puts "  Pass #{i + 1}/3..."
      result = improve_article(improved, outline[:data])
      improved = result[:data]
      total_improvement_cost += result[:cost]
    end

    log_cost("Self-Improvement (3 passes)", total_improvement_cost)

    # Output results
    output_results(improved, outline[:data])

    # Show costs
    show_costs
  end

  private

  def load_voice_profile
    # Load Twitter voice patterns
    csv_path = File.join(__dir__, "../.claude/twitter_export_real.csv")

    unless File.exist?(csv_path)
      puts "‚ö†Ô∏è  Warning: Twitter voice file not found, using defaults"
      return default_voice_profile
    end

    tweets = []
    begin
      CSV.foreach(csv_path, headers: true, liberal_parsing: true) do |row|
        tweets << row["tweet_text"] if row["tweet_text"]
      end
    rescue CSV::MalformedCSVError => e
      puts "  ‚ö†Ô∏è  Warning: Some CSV rows malformed, skipping them"
    end

    puts "  ‚úì Loaded #{tweets.compact.size} tweets for voice analysis"

    {
      sample_tweets: tweets.compact.sample(10).join("\n\n"),
      patterns: extract_voice_patterns(tweets.compact)
    }
  end

  def extract_voice_patterns(tweets)
    # Analyze tweets for patterns
    {
      uses_lowercase_i: tweets.any? { |t| t&.include?(" i ") || t&.start_with?("i ") },
      casual_profanity: tweets.any? { |t| t&.match?(/\b(fuck|shit|damn)\b/i) },
      direct_style: true,
      short_sentences: true,
      self_aware: tweets.any? { |t| t&.match?(/turns out|wild to see|kind of funny/i) }
    }
  end

  def default_voice_profile
    {
      sample_tweets: "",
      patterns: {
        uses_lowercase_i: true,
        casual_profanity: true,
        direct_style: true,
        short_sentences: true,
        self_aware: true
      }
    }
  end

  def research_serp
    puts "  Fetching Google search results via API..."

    # Step 1: Fetch Google results via Custom Search API
    search_results = scrape_google(@keyword)

    if search_results.empty?
      puts "  ‚ùå No search results found"
      return { data: nil, cost: 0 }
    end

    puts "  ‚úì Found #{search_results.size} results from Google"

    # Step 1.5: Scrape actual content from top 10 results
    puts "  Fetching full content from top 10 articles..."
    top_articles = fetch_article_content(search_results.take(10))
    puts "  ‚úì Successfully fetched #{top_articles.size} articles"

    # Step 2: Analyze in batches (Gemini output limit is 8K tokens)
    puts "  Analyzing articles in batches..."

    all_examples = []
    all_stats = []

    # Process in batches of 3 articles each
    top_articles.each_slice(3).with_index do |batch, i|
      result = analyze_article_batch(batch, i + 1)
      all_examples.concat(result[:examples] || [])
      all_stats.concat(result[:stats] || [])
    end

    puts "  ‚úì Extracted #{all_examples.size} examples total"
    puts "  ‚úì Extracted #{all_stats.size} statistics total"

    # Step 3: Final analysis for topics and gaps
    prompt = <<~PROMPT
      Analyze these top Google search results for "#{@keyword}":

      #{search_results.map.with_index do |result, i|
        "#{i+1}. #{result[:title]}\n   URL: #{result[:url]}\n   Snippet: #{result[:snippet]}\n"
      end.join("\n")}

      EXTRACTED EXAMPLES FROM ARTICLES:
      #{all_examples.map { |ex| "- #{ex['company']}: #{ex['what_they_did']} ‚Üí #{ex['outcome']}" }.join("\n")}

      EXTRACTED STATISTICS FROM ARTICLES:
      #{all_stats.map { |stat| "- #{stat['stat']} (#{stat['source']})" }.join("\n")}

      Based on the search results and extracted data, analyze:

      Format your response as JSON:
      {
        "common_topics": ["topics that appear in multiple articles based on titles/snippets"],
        "content_gaps": ["topics that could be covered but aren't mentioned"],
        "average_word_count": #{(top_articles.map { |a| a[:word_count] }.sum.to_f / top_articles.size).to_i},
        "recommended_approach": "how to beat these results with better content"
      }
    PROMPT

    response = call_ai(prompt, model: "gemini-2.5-flash")

    if response.nil? || response.empty?
      puts "  ‚ö†Ô∏è  Gemini returned empty response"
      return { data: nil, cost: 0.10 }
    end

    json_str = extract_json(response)
    if json_str.nil?
      puts "  ‚ö†Ô∏è  Could not extract JSON from response"
      puts "  Response preview: #{response[0..500]}"
      return { data: nil, cost: 0.10 }
    end

    data = JSON.parse(json_str)

    # Add the extracted examples and stats
    data['detailed_examples'] = all_examples
    data['statistics'] = all_stats

    puts "  ‚úì Found #{data['common_topics']&.size || 0} common topics"
    puts "  ‚úì Identified #{data['content_gaps']&.size || 0} content gaps"

    { data: data, cost: 0.20 } # Gemini analysis with batching (~5 calls for 10 articles)
  end

  def analyze_article_batch(articles, batch_num)
    puts "    Batch #{batch_num}: Analyzing #{articles.size} articles..."

    prompt = <<~PROMPT
      Extract examples and statistics from these articles:

      #{articles.map.with_index do |article, i|
        content_preview = article[:content][0..5000]
        "=== ARTICLE: #{article[:title]} (#{article[:word_count]} words) ===\n#{content_preview}\n\n"
      end.join("\n")}

      IMPORTANT: Extract ALL examples and statistics you find.

      Format your response as JSON:
      {
        "examples": [
          {
            "company": "Dropbox",
            "what_they_did": "created a demo video to validate their idea",
            "outcome": "got 75,000 signups overnight",
            "relevance": "MVP validation"
          }
        ],
        "stats": [
          {
            "stat": "42% of startups fail due to no market need",
            "source": "CB Insights",
            "context": "why validation matters"
          }
        ]
      }

      Extract every example and statistic you can find.
    PROMPT

    response = call_ai(prompt, model: "gemini-2.5-flash")
    json_str = extract_json(response)

    return { examples: [], stats: [] } if json_str.nil?

    data = JSON.parse(json_str)
    { examples: data['examples'] || [], stats: data['stats'] || [] }
  rescue => e
    puts "      ‚ö†Ô∏è  Batch #{batch_num} failed: #{e.message}"
    { examples: [], stats: [] }
  end

  def format_examples(examples)
    return 'None extracted' if examples.nil? || examples.empty?

    examples.map do |ex|
      company = ex['company'] || 'Unknown'
      what = ex['what_they_did'] || 'validated their idea'
      outcome = ex['outcome'] || 'achieved success'
      "- #{company}: #{what} ‚Üí #{outcome}"
    end.join("\n")
  end

  def format_stats(statistics)
    return 'None extracted' if statistics.nil? || statistics.empty?

    statistics.map do |stat|
      stat_text = stat['stat'] || 'No stat'
      source = stat['source'] || 'Unknown source'
      "- #{stat_text} (Source: #{source})"
    end.join("\n")
  end

  def fetch_article_content(urls)
    require 'net/http'
    require 'nokogiri'

    articles = []

    urls.each_with_index do |result, i|
      begin
        puts "    Fetching article #{i+1}/#{urls.size}..."

        uri = URI(result[:url])
        response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: uri.scheme == 'https',
                                   open_timeout: 5, read_timeout: 10) do |http|
          request = Net::HTTP::Get.new(uri)
          request["User-Agent"] = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
          http.request(request)
        end

        next unless response.code == '200'

        doc = Nokogiri::HTML(response.body)

        # Remove scripts, styles, nav, footer
        doc.css('script, style, nav, footer, header, aside, iframe').remove

        # Try to find main content
        main_content = doc.at_css('article') || doc.at_css('main') || doc.at_css('[role="main"]') || doc.at_css('body')

        # Extract text
        text = main_content.text.gsub(/\s+/, ' ').strip

        articles << {
          url: result[:url],
          title: result[:title],
          content: text,
          word_count: text.split.size
        }

      rescue => e
        puts "      ‚ö†Ô∏è  Failed to fetch #{result[:url]}: #{e.message}"
        next
      end
    end

    articles
  end

  def scrape_google(keyword)
    require 'net/http'
    require 'uri'

    # Google Custom Search JSON API
    api_key = ENV['GOOGLE_SEARCH_KEY']
    cx = ENV['GOOGLE_SEARCH_CX'] || '017576662512468239146:omuauf_lfve' # Default: general web search

    if api_key.nil? || api_key.empty?
      puts "  ‚ö†Ô∏è  GOOGLE_SEARCH_KEY not found in .env"
      return []
    end

    query = URI.encode_www_form_component(keyword)
    url = "https://www.googleapis.com/customsearch/v1?key=#{api_key}&cx=#{cx}&q=#{query}&num=10"

    uri = URI(url)
    response = Net::HTTP.get_response(uri)

    if response.code != '200'
      puts "  ‚ö†Ô∏è  Google API error: #{response.code}"
      puts "  Response: #{response.body[0..500]}" # First 500 chars
      return []
    end

    data = JSON.parse(response.body)

    if data['error']
      puts "  ‚ö†Ô∏è  Google API error: #{data['error']['message']}"
      return []
    end

    results = []
    (data['items'] || []).each do |item|
      results << {
        title: item['title'],
        url: item['link'],
        snippet: item['snippet'] || ""
      }

      break if results.size >= 10
    end

    if results.empty?
      puts "  ‚ö†Ô∏è  Google returned 0 items for this query"
    end

    results
  rescue => e
    puts "    ‚ö†Ô∏è  Google API failed: #{e.message}"
    puts "    #{e.backtrace.first}"
    []
  end

  def generate_outline(serp_data)
    puts "  Creating comprehensive outline..."

    prompt = <<~PROMPT
      You are an expert SEO content strategist.

      TARGET KEYWORD: #{@keyword}

      COMPETITIVE ANALYSIS:
      - Common topics covered: #{serp_data['common_topics']&.join(', ') || 'None'}
      - Content gaps to exploit: #{serp_data['content_gaps']&.join(', ') || 'None'}
      - Average competitor length: #{serp_data['average_word_count']} words
      - Strategy: #{serp_data['recommended_approach']}

      REAL EXAMPLES TO USE (#{serp_data['detailed_examples']&.size || 0} available):
      #{format_examples(serp_data['detailed_examples'])}

      REAL STATISTICS TO USE (#{serp_data['statistics']&.size || 0} available):
      #{format_stats(serp_data['statistics'])}

      Create a detailed article outline that will BEAT the current top results.

      REQUIREMENTS:
      1. SEO-optimized title (60 chars max, keyword at start)
      2. Compelling meta description (155 chars)
      3. Article should be #{[(serp_data['average_word_count'] * 1.2).to_i, 2000].max} words (20% longer than competitors, minimum 2000)
      4. Cover ALL common topics (to be comprehensive)
      5. Include unique angles on content gaps (to stand out)
      6. Use the REAL examples and stats provided above (don't make up new ones)
      7. Distribute examples across sections (don't repeat same company more than 2x)
      8. Identify 2-3 spots to embed interactive mini-tools
      9. Structure for featured snippets (lists, tables, Q&A)

      MINI-TOOLS AVAILABLE:
      - Persona Generator (helps identify target customers)
      - Validation Checklist (interactive checklist tool)
      - Competitor Search (find competitors for any idea)

      Format as JSON (examples and stats will be passed separately):
      {
        "title": "SEO title here",
        "meta_description": "Meta description here",
        "target_word_count": 3200,
        "sections": [
          {
            "heading": "H2 heading",
            "subheadings": ["H3 if needed"],
            "key_points": ["what to cover"],
            "word_count": 400,
            "type": "how_to|comparison|definition|standard"
          }
        ],
        "tool_placements": [
          {
            "after_section": 2,
            "tool": "persona_generator",
            "context": "why it fits here"
          }
        ]
      }
    PROMPT

    begin
      response = call_ai(prompt, model: "gemini-2.5-flash")
      data = JSON.parse(extract_json(response))

      # Add examples and stats to the outline for writers to use
      data['detailed_examples'] = serp_data['detailed_examples'] || []
      data['statistics'] = serp_data['statistics'] || []

      puts "  ‚úì Created #{data['sections']&.size || 0} sections"
      puts "  ‚úì Target: #{data['target_word_count']} words"
      puts "  ‚úì Tool placements: #{data['tool_placements']&.size || 0}"

      { data: data, cost: 0.01 } # Gemini flash for outline
    rescue => e
      puts "  ‚ùå Outline generation failed: #{e.message}"
      puts "  Debug: #{e.class}"
      { data: nil, cost: 0 }
    end
  end

  def write_article(outline)
    puts "  Writing article section by section..."

    # Write intro
    intro = write_intro(outline)

    # Write each section
    sections = outline['sections'].map.with_index do |section, i|
      puts "    Writing section #{i + 1}/#{outline['sections'].size}: #{section['heading']}"
      write_section(section, outline)
    end

    # Write conclusion
    conclusion = write_conclusion(outline)

    # Combine
    full_article = [intro, *sections, conclusion].join("\n\n")

    word_count = full_article.split.size
    puts "  ‚úì Article complete: #{word_count} words"

    { data: full_article, cost: 1.50 } # GPT-4o ~$1.50 for full article
  end

  def write_intro(outline)
    prompt = <<~PROMPT
      Write an engaging introduction for this article:

      TITLE: #{outline['title']}
      KEYWORD: #{@keyword}
      ARTICLE OUTLINE: #{outline['sections'].map { |s| s['heading'] }.join(", ")}

      REAL EXAMPLES YOU CAN USE (from competitor research):
      #{format_examples(outline['detailed_examples'])}

      REAL STATISTICS YOU CAN USE (from competitor research):
      #{format_stats(outline['statistics'])}

      CRITICAL RULES:
      - ONLY use examples and stats from the list above (DO NOT make up new ones)
      - DO NOT make up statistics, percentages, or specific numbers
      - Use examples naturally in the intro - don't force them if they don't fit
      - Save variety for later sections (don't use all examples in the intro)
      - If you don't have a relevant stat, use general language ("many startups", "most founders")

      REQUIREMENTS:
      - Hook reader in first sentence
      - Mention keyword in first 100 words
      - Set up what the article will cover
      - 150-200 words
      - Use this voice profile (but with proper grammar):

      #{voice_instructions}

      EXAMPLE OF THE VOICE (from actual tweets):
      #{@voice_profile[:sample_tweets]}

      Write the introduction now.
    PROMPT

    call_ai(prompt, model: "gpt-4o")
  end

  def write_section(section, outline)
    type = section['type'] || 'standard'

    prompt = build_section_prompt(section, type, outline)

    call_ai(prompt, model: "gpt-4o")
  end

  def build_section_prompt(section, type, outline)
    base_prompt = <<~PROMPT
      Write a detailed section for an article about "#{@keyword}"

      SECTION HEADING: #{section['heading']}
      KEY POINTS TO COVER:
      #{section['key_points']&.join("\n") || 'See context'}

      TARGET WORD COUNT: #{section['word_count']} words

      REAL EXAMPLES YOU CAN USE (from competitor research):
      #{format_examples(outline['detailed_examples'])}

      REAL STATISTICS YOU CAN USE (from competitor research):
      #{format_stats(outline['statistics'])}

      CRITICAL RULES:
      - ONLY use examples and stats from the list above (DO NOT make up new ones)
      - DO NOT make up statistics, percentages, or specific numbers
      - Use examples naturally where they fit - don't force them into every section
      - Vary which examples you use across sections (avoid repetition)
      - If no relevant example fits, use general language instead ("many startups", "founders often")
      - Quality over quantity - better to skip an example than force it awkwardly

      #{type_specific_instructions(type)}

      VOICE GUIDELINES (maintain proper grammar):
      #{voice_instructions}

      EXAMPLE VOICE (from actual tweets):
      #{@voice_profile[:sample_tweets]}

      Write the section now in markdown format.
    PROMPT
  end

  def type_specific_instructions(type)
    case type
    when "how_to"
      <<~INST
        FORMAT: Step-by-step instructions
        - Number each step
        - Make each step actionable
        - Include examples
        - Add "common mistakes" callout
      INST
    when "comparison"
      <<~INST
        FORMAT: Comparison/analysis
        - Use tables if comparing features
        - List pros and cons
        - Be objective but opinionated
      INST
    when "definition"
      <<~INST
        FORMAT: Clear explanation
        - Start with simple definition
        - Explain "why it matters"
        - Give real examples
      INST
    else
      "FORMAT: Standard informational section"
    end
  end

  def voice_instructions
    patterns = @voice_profile[:patterns]

    <<~VOICE
      YOUR VOICE PROFILE:
      - Direct and conversational (like explaining to a founder friend)
      - Short, punchy sentences (max 3 sentences per paragraph)
      - Use "you" and "your" (not "one should...")
      #{patterns[:uses_lowercase_i] ? '- Lowercase "i" when referring to yourself' : ''}
      #{patterns[:self_aware] ? '- Self-aware phrases like "turns out", "wild to see", "kind of funny"' : ''}
      - Real examples (name actual companies when possible)
      - No marketing jargon or corporate speak

      CRITICAL - DO NOT:
      - Use profanity or cursing (keep it professional)
      - Use AI tells: "delve", "unlock", "harness", "revolutionize", "dive deep"
      - Start sentences with "In today's..." or "It's worth noting..."
      - Write long academic paragraphs
      - Be overly formal or robotic
      - Use generic examples ("imagine you're building a SaaS...")

      MAINTAIN:
      - Proper grammar and spelling
      - Clear sentence structure
      - Professional but conversational tone
    VOICE
  end

  def write_conclusion(outline)
    prompt = <<~PROMPT
      Write a conclusion for this article:

      TITLE: #{outline['title']}
      KEYWORD: #{@keyword}
      SECTIONS COVERED: #{outline['sections'].map { |s| s['heading'] }.join(", ")}

      CRITICAL RULES:
      - DO NOT make up statistics or specific numbers
      - Use general language when summarizing ("many founders", "most startups")
      - Don't cite data unless it was provided earlier in the article

      REQUIREMENTS:
      - Summarize key takeaways (2-3 bullets)
      - Include call-to-action (try our validation tool)
      - 150-200 words
      - Use voice profile:

      #{voice_instructions}

      Write the conclusion now.
    PROMPT

    call_ai(prompt, model: "gpt-4o")
  end

  def improve_article(article, outline)
    puts "  Analyzing article for quality issues..."

    prompt = <<~PROMPT
      You are an expert content editor. Review this article and identify any issues:

      ARTICLE:
      #{article}

      GUIDELINES IT SHOULD FOLLOW:
      - No profanity or cursing
      - Each company example used maximum 2 times
      - No made-up statistics
      - No AI language ("delve", "unlock", "harness", "revolutionize")
      - Professional but conversational tone
      - Short paragraphs (max 3 sentences)

      ANALYZE AND FIX:
      1. Are any companies mentioned too frequently? (More than 2x total)
      2. Is there any profanity that should be removed?
      3. Are there any AI clich√© words or phrases ("delve", "unlock", "harness")?
      4. Are paragraphs too long? (Max 3 sentences)
      5. Does anything sound made-up or unsourced?
      6. Are conversational phrases overused? (e.g., "surprising" 5x)

      IMPORTANT VARIETY RULES:
      - If replacing conversational phrases, use DIFFERENT words each time:
        - First instance: "surprising"
        - Second: "interesting"
        - Third: "notable"
        - Or keep some original phrases like "turns out" (those are fine)
      - Don't replace the same phrase with the same word everywhere

      CRITICAL: Return ONLY the improved article text.
      Do NOT include meta-commentary like "Here is the revised version" or "ARTICLE:".
      Do NOT wrap your response in markdown code blocks.
      Start directly with the article content.
      Only make necessary fixes - don't rewrite sections that are fine.
      Keep the same structure and markdown formatting.
    PROMPT

    response = call_ai(prompt, model: "gpt-4o")  # Uses default 16K max tokens

    # Clean up any meta-commentary that leaked through
    cleaned = clean_meta_commentary(response)

    # Count improvements made
    puts "  ‚úì Article improved and polished"

    { data: cleaned, cost: 0.30 } # GPT-4o review pass
  end

  def clean_meta_commentary(text)
    # Remove common GPT-4o meta-commentary patterns
    cleaned = text.dup

    # Remove "Here is the revised version..." type headers
    cleaned = cleaned.gsub(/^Here is the (revised|improved|edited|updated) (version|article).*?\n+---\n+/mi, '')
    cleaned = cleaned.gsub(/^ARTICLE:\n+/mi, '')

    # Remove leading/trailing markdown code blocks if present
    cleaned = cleaned.gsub(/^```markdown\n/m, '')
    cleaned = cleaned.gsub(/^```\n/m, '')
    cleaned = cleaned.gsub(/\n```$/m, '')

    cleaned.strip
  end

  def add_tool_placeholders(article, outline)
    result = article

    outline['tool_placements']&.each do |placement|
      tool_markup = generate_tool_placeholder(placement)

      # Insert after specified section
      # For MVP, just append at end
      result += "\n\n#{tool_markup}"
    end

    result
  end

  def generate_tool_placeholder(placement)
    tool_name = placement['tool']
    context = placement['context']

    <<~TOOL
      ---

      ## üõ†Ô∏è Interactive Tool: #{tool_name.split('_').map(&:capitalize).join(' ')}

      *#{context}*

      [PLACEHOLDER - Tool will be embedded here]

      **Features:**
      - Free to use
      - Instant results
      - Export your data

      üëâ [Try it now](#)

      ---
    TOOL
  end

  def call_ai_with_search(prompt, model:)
    require 'net/http'
    require 'json'

    puts "    Calling GPT-5 with web search..."

    api_key = ENV["OPENAI_API_KEY"]
    uri = URI("https://api.openai.com/v1/responses")

    request = Net::HTTP::Post.new(uri)
    request["Content-Type"] = "application/json"
    request["Authorization"] = "Bearer #{api_key}"

    request.body = {
      model: "gpt-5",
      reasoning: { effort: "low" },
      tools: [
        {
          type: "web_search"
        }
      ],
      tool_choice: "auto",
      include: ["web_search_call.action.sources"],
      input: prompt
    }.to_json

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    result = JSON.parse(response.body)

    if result["error"]
      puts "    ‚ö†Ô∏è  OpenAI Error: #{result["error"]["message"]}"
      # Fall back to mock data if web search not available
      return fallback_serp_data
    end

    # GPT-5 responses endpoint has different structure
    content = result.dig("output", "content") || result.dig("choices", 0, "message", "content")
    content
  rescue => e
    puts "    ‚ö†Ô∏è  API Error: #{e.message}"
    puts "    Using fallback SERP data..."
    fallback_serp_data
  end

  def fallback_serp_data
    {
      "top_results" => [
        {
          "url" => "https://example.com/1",
          "topics" => ["Define idea validation", "Why validation matters", "Validation methods", "Common mistakes"],
          "structure" => ["Introduction", "What is validation", "How to validate", "Tools", "Conclusion"],
          "estimated_words" => 2500,
          "has_tools" => false
        },
        {
          "url" => "https://example.com/2",
          "topics" => ["Customer interviews", "Market research", "MVP testing", "Feedback loops"],
          "structure" => ["Overview", "Interview guide", "Research methods", "Testing strategies"],
          "estimated_words" => 3000,
          "has_tools" => true
        }
      ],
      "common_topics" => ["What is idea validation", "Customer interviews", "Market research", "MVP testing", "Common mistakes"],
      "content_gaps" => ["Using AI for validation", "Automated validation tools", "Market intelligence analysis"],
      "average_word_count" => 2750,
      "recommended_approach" => "Cover all common topics but add unique angle on AI-powered validation and market intelligence"
    }.to_json
  end

  def call_ai(prompt, model:, max_tokens: nil)
    require 'net/http'
    require 'json'

    api_key = if model.include?("gemini")
      ENV["GEMINI_API_KEY"]
    else
      ENV["OPENAI_API_KEY"]
    end

    if model.include?("gemini")
      call_gemini(prompt, api_key, max_tokens)
    else
      call_openai(prompt, api_key, model, max_tokens)
    end
  end

  def call_openai(prompt, api_key, model, max_tokens = nil)
    uri = URI("https://api.openai.com/v1/chat/completions")

    request = Net::HTTP::Post.new(uri)
    request["Content-Type"] = "application/json"
    request["Authorization"] = "Bearer #{api_key}"

    request.body = {
      model: model,
      messages: [ { role: "user", content: prompt } ],
      temperature: 0.7,
      max_tokens: max_tokens || 16000  # GPT-4o max output tokens
    }.to_json

    response = Net::HTTP.start(uri.hostname, uri.port,
                                use_ssl: true,
                                read_timeout: 180,
                                open_timeout: 30) do |http|
      http.request(request)
    end

    result = JSON.parse(response.body)

    if result["error"]
      puts "    ‚ö†Ô∏è  OpenAI Error: #{result["error"]["message"]}"
      return generate_fallback_response(prompt)
    end

    result.dig("choices", 0, "message", "content")
  rescue => e
    puts "    ‚ö†Ô∏è  API Error: #{e.message}"
    generate_fallback_response(prompt)
  end

  def call_gemini(prompt, api_key, max_tokens = nil)
    require 'net/http'
    require 'json'

    uri = URI("https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=#{api_key}")

    request = Net::HTTP::Post.new(uri)
    request["Content-Type"] = "application/json"

    request.body = {
      contents: [{
        parts: [{ text: prompt }]
      }],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: max_tokens || 65000  # Gemini 2.5 Flash max output tokens
      }
    }.to_json

    response = Net::HTTP.start(uri.hostname, uri.port,
                                use_ssl: true,
                                read_timeout: 180,
                                open_timeout: 30) do |http|
      http.request(request)
    end

    result = JSON.parse(response.body)

    if result["error"]
      puts "    ‚ö†Ô∏è  Gemini Error: #{result["error"]["message"]}"
      return generate_fallback_response(prompt)
    end

    result.dig("candidates", 0, "content", "parts", 0, "text")
  rescue => e
    puts "    ‚ö†Ô∏è  API Error: #{e.message}"
    generate_fallback_response(prompt)
  end

  def generate_fallback_response(prompt)
    # Return realistic placeholder based on what's being requested
    if prompt.include?("outline")
      return generate_mock_outline
    elsif prompt.include?("introduction")
      return generate_mock_intro
    elsif prompt.include?("conclusion")
      return generate_mock_conclusion
    else
      return generate_mock_section(prompt)
    end
  end

  def generate_mock_outline
    {
      "title" => "How to Validate a Startup Idea (Complete Guide for 2025)",
      "meta_description" => "Learn how to validate your startup idea before building. Step-by-step guide with customer interviews, market research, and AI-powered validation tools.",
      "target_word_count" => 3300,
      "sections" => [
        {
          "heading" => "What is Startup Idea Validation?",
          "subheadings" => [],
          "key_points" => ["Define validation", "Why it matters", "Cost of skipping validation"],
          "word_count" => 400,
          "type" => "definition"
        },
        {
          "heading" => "Step 1: Identify Your Target Customer",
          "subheadings" => ["Create customer personas", "Validate assumptions"],
          "key_points" => ["Who has the problem", "Willingness to pay", "Where to find them"],
          "word_count" => 500,
          "type" => "how_to"
        },
        {
          "heading" => "Step 2: Conduct Customer Interviews",
          "subheadings" => ["Interview preparation", "Questions to ask", "Analyzing feedback"],
          "key_points" => ["Interview script", "Common mistakes", "Red flags"],
          "word_count" => 600,
          "type" => "how_to"
        },
        {
          "heading" => "Step 3: Research Your Market and Competitors",
          "subheadings" => ["Market size", "Competition analysis", "Finding your niche"],
          "key_points" => ["Is market big enough", "Who else solves this", "Differentiation"],
          "word_count" => 500,
          "type" => "how_to"
        },
        {
          "heading" => "Step 4: Test with an MVP",
          "subheadings" => ["What is an MVP", "Building vs faking", "Measuring success"],
          "key_points" => ["Minimum viable product", "Landing page tests", "Metrics that matter"],
          "word_count" => 500,
          "type" => "how_to"
        },
        {
          "heading" => "Using AI Tools for Faster Validation",
          "subheadings" => ["Market intelligence", "Automated persona generation", "Competitive analysis"],
          "key_points" => ["AI-powered validation", "Tools comparison", "Tool approaches"],
          "word_count" => 400,
          "type" => "standard"
        },
        {
          "heading" => "Common Validation Mistakes to Avoid",
          "subheadings" => [],
          "key_points" => ["Confirmation bias", "Only talking to friends", "Asking wrong questions"],
          "word_count" => 400,
          "type" => "standard"
        }
      ],
      "tool_placements" => [
        {
          "after_section" => 1,
          "tool" => "persona_generator",
          "context" => "Readers just learned about target customers, perfect time to help them generate personas"
        },
        {
          "after_section" => 5,
          "tool" => "validation_checklist",
          "context" => "After learning all steps, give them a checklist to track their validation progress"
        }
      ]
    }.to_json
  end

  def generate_mock_intro
    <<~INTRO
      most founders skip validation because they're scared.

      not scared of building the wrong thing - scared of hearing "nobody wants this" before they've even started. so they spend 6 months building, launch to crickets, and then hear it anyway.

      turns out validation is way less painful than building something nobody asked for.

      this guide walks through exactly how to validate your startup idea before writing a single line of code. you'll learn how to find target customers, run effective interviews, analyze your market, and use AI tools to speed up the whole process.

      whether you're a first-time founder or on your fifth startup, these validation steps will save you months of wasted effort.
    INTRO
  end

  def generate_mock_section(prompt)
    # Extract heading from prompt if possible
    heading = prompt[/SECTION HEADING: (.+)/, 1] || "Section"

    <<~SECTION
      ## #{heading}

      here's the thing about #{heading.downcase} - most people overcomplicate it.

      you don't need months of research or expensive consultants. you just need to talk to real people who have the problem you're solving.

      the process is simple:

      1. **Identify 10-15 potential customers.** These are people who currently have the pain point your product solves. Not friends or family - actual strangers in your target market.

      2. **Reach out with a specific ask.** Don't pitch your idea. Ask to learn about their current workflow and pain points. "Hey, i'm researching how [target audience] handles [problem]. Could i ask you a few questions?"

      3. **Listen more than you talk.** Your job is to understand their world, not convince them your solution is brilliant. Ask open-ended questions like "how do you currently solve this?" and "what's most frustrating about that approach?"

      4. **Look for patterns.** After 10 conversations, you'll start seeing the same problems and objections. That's your signal.

      the biggest mistake? asking "would you buy this?" People lie to be nice. Better question: "what are you using today?" If they're not solving the problem at all, or they're happy with their current solution, that's valuable data.

      turns out validation isn't about getting people to say "yes i'd buy that." it's about finding people who are actively looking for a better solution to a problem they already have.
    SECTION
  end

  def generate_mock_conclusion
    <<~CONCLUSION
      ## Next Steps

      validation isn't a one-time checkbox. it's an ongoing conversation with your market.

      here's what to do after reading this:

      - **This week:** Identify 10 potential customers and reach out for interviews
      - **This month:** Analyze patterns and validate your core assumptions
      - **Before building:** Make sure at least 30% of people you talk to are actively looking for a solution

      if you want to speed up the process, try using AI validation tools. they can help generate customer personas, identify objections, and analyze your market - giving you validation insights in minutes instead of weeks.

      most importantly: don't skip this step. the 2-3 weeks you spend on validation will save you 6-12 months of building something nobody wants.

      now go validate.
    CONCLUSION
  end

  def extract_json(response)
    # Extract JSON from AI response (might be wrapped in markdown)
    if response.include?("```json")
      # Try with closing backticks first
      json = response[/```json\s*(.+?)\s*```/m, 1]
      if json.nil?
        # Fallback: extract from ```json to end
        json = response[/```json\s*(.+)/m, 1]
      end
      json
    elsif response.include?("```")
      json = response[/```\s*(.+?)\s*```/m, 1]
      if json.nil?
        json = response[/```\s*(.+)/m, 1]
      end
      json
    elsif response.include?("{")
      # Try to extract JSON object directly
      response[/(\{.+\})/m, 1]
    else
      response
    end
  end

  def log_cost(step, amount)
    @costs << { step: step, amount: amount }
  end

  def show_costs
    puts "\n" + "=" * 80
    puts "üí∞ COST BREAKDOWN"
    puts "=" * 80

    @costs.each do |cost|
      printf "%-30s $%.2f\n", cost[:step], cost[:amount]
    end

    total = @costs.sum { |c| c[:amount] }
    puts "-" * 80
    printf "%-30s $%.2f\n", "TOTAL", total

    if total > 5.0
      puts "\n‚ö†Ô∏è  Warning: Cost exceeded $5 budget"
    else
      puts "\n‚úÖ Under $5 budget"
    end
  end

  def output_results(article, outline)
    puts "\n" + "=" * 80
    puts "üìÑ GENERATED ARTICLE"
    puts "=" * 80

    puts "\nTITLE: #{outline['title']}"
    puts "META: #{outline['meta_description']}"
    puts "TARGET WORDS: #{outline['target_word_count']}"
    puts "ACTUAL WORDS: #{article.split.size}"
    puts "\n" + "-" * 80

    # Build full markdown with reasoning/logic
    full_markdown = build_markdown_with_reasoning(article, outline)

    # Save to file
    filename = "article_#{@keyword.gsub(' ', '_')}_#{Time.now.strftime('%Y%m%d_%H%M%S')}.md"
    File.write(filename, full_markdown)

    puts "\n‚úÖ Article saved to: #{filename}"
    puts "\nPREVIEW:"
    puts "-" * 80
    puts article[0..500] + "..."
    puts "-" * 80
    puts "\n[Full article saved to #{filename}]"
  end

  def build_markdown_with_reasoning(article, outline)
    <<~MARKDOWN
      # #{outline['title']}

      ## üìä Article Generation Logic

      **Target Keyword:** #{@keyword}
      **Word Count Target:** #{outline['target_word_count']} words
      **Actual Word Count:** #{article.split.size} words

      ### Why This Outline?

      #{outline['sections'].map.with_index do |section, i|
        "**Section #{i+1}: #{section['heading']}**\n" +
        "- Type: #{section['type']}\n" +
        "- Word count: #{section['word_count']}\n" +
        "- Key points: #{section['key_points']&.join(', ')}\n"
      end.join("\n")}

      ### Tool Placements:

      #{outline['tool_placements']&.map do |placement|
        "- **#{placement['tool']}** after section #{placement['after_section']}\n" +
        "  Reasoning: #{placement['context']}"
      end&.join("\n") || 'No tools placed'}

      ---

      # The Article

      #{article}

      ---

      ## üìà SEO Strategy

      **Meta Title:** #{outline['title']} (#{outline['title'].length} chars)
      **Meta Description:** #{outline['meta_description']} (#{outline['meta_description'].length} chars)

      **Target Features:**
      - Featured snippet optimization: #{outline['sections'].any? { |s| s['type'] == 'how_to' } ? 'Yes (numbered lists)' : 'No'}
      - FAQ sections: #{outline['sections'].any? { |s| s['heading'].include?('Common') || s['heading'].include?('Mistakes') } ? 'Yes' : 'No'}
      - Table opportunities: #{outline['sections'].any? { |s| s['type'] == 'comparison' } ? 'Yes' : 'No'}
    MARKDOWN
  end
end

# Run it
if ARGV.empty?
  puts "Usage: bin/generate_article \"your keyword here\""
  puts "Example: bin/generate_article \"how to validate startup idea\""
  exit 1
end

keyword = ARGV.join(" ")
ArticleGenerator.new(keyword).generate
